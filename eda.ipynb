{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2c13eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook is working\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "print(\"Notebook is working\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd3dfce",
   "metadata": {},
   "source": [
    "**Data source:** https://www.kaggle.com/datasets/bytadit/ecommerce-order-dataset/data\n",
    "\n",
    "# **1. Introduction**\n",
    "I have 2 purposes for this project. To further practice data analysis with python and to do analysis on an ecommerce and supply chain dataset. \n",
    "\n",
    "The purpose of this project is to epxlore an ecommerce and supply chain dataset and find areas to analyze. Below is a list of the sections in this notebook:\n",
    "\n",
    "1. Data inspection\n",
    "2. Finding areas of inspection\n",
    "3. Data processing and analysis\n",
    "4. Conclusion\n",
    "\n",
    "---\n",
    "\n",
    "# **2. Data Inspection**\n",
    "Before doing anything else, let's check the datasets that we have in the `data` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c373c19d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\2. Areas\\\\Career_Exploration\\\\Data_Analyst\\\\ecommerce_sc_dataset'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Current working directory\n",
    "os.listdir(\"data\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfb6325",
   "metadata": {},
   "source": [
    "Our dataset seems to be intended for machine learning as it is split into training and test data. For this specific project we'll focus mainly on EDA, wo we will not be modifying the data in any way. Thus it is safe to combine them both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0ec3d634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get into 'train' working directory\n",
    "os.chdir(\"d:\\\\2. Areas\\\\Career_Exploration\\\\Data_Analyst\\\\ecommerce_sc_dataset\\\\data\\\\train\")\n",
    "os.listdir(\".\")\n",
    "\n",
    "# Reading the files into python\n",
    "df_tr_cust = pd.read_csv(\"train_Customers.csv\")\n",
    "df_tr_ordItems = pd.read_csv(\"train_OrderItems.csv\")\n",
    "df_tr_orders = pd.read_csv(\"train_Orders.csv\")\n",
    "df_tr_payments = pd.read_csv(\"train_Payments.csv\")\n",
    "df_tr_products = pd.read_csv(\"train_Products.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c604be0",
   "metadata": {},
   "source": [
    "Now the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3da89f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get into 'test' working directory\n",
    "os.chdir(\"d:\\\\2. Areas\\\\Career_Exploration\\\\Data_Analyst\\\\ecommerce_sc_dataset\\\\data\\\\test\")\n",
    "os.listdir(\".\")\n",
    "\n",
    "# Reading the files into python\n",
    "df_ts_cust = pd.read_csv(\"test_customers.csv\")\n",
    "df_ts_ordItems = pd.read_csv(\"test_OrderItems.csv\")\n",
    "df_ts_orders = pd.read_csv(\"test_Orders.csv\")\n",
    "df_ts_payments = pd.read_csv(\"test_Payments.csv\")\n",
    "df_ts_products = pd.read_csv(\"test_Products.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06731d64",
   "metadata": {},
   "source": [
    "Now that we have the data in python, we will now create copies and work with them instead of the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e1a131df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create copies\n",
    "df_cust = pd.concat([df_ts_cust.copy(),df_tr_cust.copy()], ignore_index=True)\n",
    "df_ordItems = pd.concat([df_ts_ordItems.copy(),df_tr_ordItems.copy()], ignore_index=True)\n",
    "df_orders = pd.concat([df_ts_orders.copy(),df_tr_orders.copy()], ignore_index=True)\n",
    "df_payments = pd.concat([df_ts_payments.copy(),df_tr_payments.copy()], ignore_index=True)\n",
    "df_products = pd.concat([df_ts_products.copy(),df_tr_products.copy()], ignore_index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
