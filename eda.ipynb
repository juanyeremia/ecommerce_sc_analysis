{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b2c13eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook is working\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "print(\"Notebook is working\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd3dfce",
   "metadata": {},
   "source": [
    "**Data source:** https://www.kaggle.com/datasets/bytadit/ecommerce-order-dataset/data\n",
    "\n",
    "# **1. Introduction**\n",
    "I have 2 purposes for this project. To further practice data analysis with python and to do analysis on an ecommerce and supply chain dataset. \n",
    "\n",
    "The purpose of this project is to epxlore an ecommerce and supply chain dataset and find areas to analyze. Below is a list of the sections in this notebook:\n",
    "\n",
    "1. Data inspection\n",
    "2. Finding areas of inspection\n",
    "3. Data processing and analysis\n",
    "4. Conclusion\n",
    "\n",
    "---\n",
    "\n",
    "# **2. Data Inspection**\n",
    "Before doing anything else, let's check the datasets that we have in the `data` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c373c19d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[105]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Current working directory\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m os.getcwd()\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [WinError 3] The system cannot find the path specified: 'data'"
     ]
    }
   ],
   "source": [
    "# Current working directory\n",
    "os.listdir(\"data\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfb6325",
   "metadata": {},
   "source": [
    "Our dataset seems to be intended for machine learning as it is split into training and test data. For this specific project we'll focus mainly on EDA, wo we will not be modifying the data in any way. Thus it is safe to combine them both.\n",
    "\n",
    "## 2.1. Concatenating datasets\n",
    "First, let's read the training data into python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec3d634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get into 'train' working directory\n",
    "os.chdir(\"d:\\\\2. Areas\\\\Career_Exploration\\\\Data_Analyst\\\\ecommerce_sc_dataset\\\\data\\\\train\")\n",
    "os.listdir(\".\")\n",
    "\n",
    "# Reading the files into python\n",
    "df_tr_cust = pd.read_csv(\"train_Customers.csv\")\n",
    "df_tr_ordItems = pd.read_csv(\"train_OrderItems.csv\")\n",
    "df_tr_orders = pd.read_csv(\"train_Orders.csv\")\n",
    "df_tr_payments = pd.read_csv(\"train_Payments.csv\")\n",
    "df_tr_products = pd.read_csv(\"train_Products.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c604be0",
   "metadata": {},
   "source": [
    "Now the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da89f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get into 'test' working directory\n",
    "os.chdir(\"d:\\\\2. Areas\\\\Career_Exploration\\\\Data_Analyst\\\\ecommerce_sc_dataset\\\\data\\\\test\")\n",
    "os.listdir(\".\")\n",
    "\n",
    "# Reading the files into python\n",
    "df_ts_cust = pd.read_csv(\"test_customers.csv\")\n",
    "df_ts_ordItems = pd.read_csv(\"test_OrderItems.csv\")\n",
    "df_ts_orders = pd.read_csv(\"test_Orders.csv\")\n",
    "df_ts_payments = pd.read_csv(\"test_Payments.csv\")\n",
    "df_ts_products = pd.read_csv(\"test_Products.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06731d64",
   "metadata": {},
   "source": [
    "Now that we have the data in python, we will now create copies and work with them instead of the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a131df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create copies\n",
    "df_cust = pd.concat([df_ts_cust.copy(),df_tr_cust.copy()], ignore_index=True)\n",
    "df_ordItems = pd.concat([df_ts_ordItems.copy(),df_tr_ordItems.copy()], ignore_index=True)\n",
    "df_orders = pd.concat([df_ts_orders.copy(),df_tr_orders.copy()], ignore_index=True)\n",
    "df_payments = pd.concat([df_ts_payments.copy(),df_tr_payments.copy()], ignore_index=True)\n",
    "df_products = pd.concat([df_ts_products.copy(),df_tr_products.copy()], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01636cbb",
   "metadata": {},
   "source": [
    "The code below will export the combined databases/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8f594a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data for temp checkings\n",
    "df_cust.to_csv(\"comb_cust.csv\")\n",
    "df_ordItems.to_csv(\"comb_ordItems.csv\")\n",
    "df_orders.to_csv(\"comb_orders.csv\")\n",
    "df_payments.to_csv(\"comb_payments.csv\")\n",
    "df_products.to_csv(\"comb_prodcuts.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5de818",
   "metadata": {},
   "source": [
    "## 2.2. Inspection\n",
    "Now that we have all the datasets combined, let's inspect each one.\n",
    "\n",
    "#### Customer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a06f3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 127595 entries, 0 to 127594\n",
      "Data columns (total 4 columns):\n",
      " #   Column                    Non-Null Count   Dtype \n",
      "---  ------                    --------------   ----- \n",
      " 0   customer_id               127595 non-null  object\n",
      " 1   customer_zip_code_prefix  127595 non-null  int64 \n",
      " 2   customer_city             127595 non-null  object\n",
      " 3   customer_state            127595 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 3.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_cust.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6f2a04",
   "metadata": {},
   "source": [
    "The combined customer has:\n",
    "\n",
    "- 4 columns and 127,594 row\n",
    "- no missing values\n",
    "- correct data types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7461cc6",
   "metadata": {},
   "source": [
    "#### Order Items data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745c97fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 127595 entries, 0 to 127594\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   order_id          127595 non-null  object \n",
      " 1   product_id        127595 non-null  object \n",
      " 2   seller_id         127595 non-null  object \n",
      " 3   price             127595 non-null  float64\n",
      " 4   shipping_charges  127595 non-null  float64\n",
      "dtypes: float64(2), object(3)\n",
      "memory usage: 4.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_ordItems.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46cc926",
   "metadata": {},
   "source": [
    "This combined order items data has:\n",
    "\n",
    "- 5 columns and 125,594 rows\n",
    "- no missing values\n",
    "- correct data types\n",
    "\n",
    "#### Order data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97d9a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 127595 entries, 0 to 127594\n",
      "Data columns (total 7 columns):\n",
      " #   Column                         Non-Null Count   Dtype \n",
      "---  ------                         --------------   ----- \n",
      " 0   order_id                       127595 non-null  object\n",
      " 1   customer_id                    127595 non-null  object\n",
      " 2   order_purchase_timestamp       127595 non-null  object\n",
      " 3   order_approved_at              127579 non-null  object\n",
      " 4   order_status                   89316 non-null   object\n",
      " 5   order_delivered_timestamp      87427 non-null   object\n",
      " 6   order_estimated_delivery_date  89316 non-null   object\n",
      "dtypes: object(7)\n",
      "memory usage: 6.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_orders.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960fa0a3",
   "metadata": {},
   "source": [
    "This combined order data has:\n",
    "\n",
    "- 7 columns and 127,594 rows\n",
    "- missing values in columns `order_approved_at`, `order_status`, `order_delivered_timestamp`, and `order_estimated_delivery_date`.\n",
    "- correct data types, however dates and timestamps will need to be covnerted into their proper formats in the processing.\n",
    "\n",
    "#### Payments data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2e5602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 127595 entries, 0 to 127594\n",
      "Data columns (total 5 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   order_id              127595 non-null  object \n",
      " 1   payment_sequential    127595 non-null  int64  \n",
      " 2   payment_type          127595 non-null  object \n",
      " 3   payment_installments  127595 non-null  int64  \n",
      " 4   payment_value         127595 non-null  float64\n",
      "dtypes: float64(1), int64(2), object(2)\n",
      "memory usage: 4.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_payments.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1b5811",
   "metadata": {},
   "source": [
    "This combined payments data has:\n",
    "\n",
    "- 5 columns and 127,594 rows\n",
    "- no missing values\n",
    "- correct data types\n",
    "\n",
    "#### Products data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e05c8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 127595 entries, 0 to 127594\n",
      "Data columns (total 6 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   product_id             127595 non-null  object \n",
      " 1   product_category_name  127119 non-null  object \n",
      " 2   product_weight_g       127570 non-null  float64\n",
      " 3   product_length_cm      127570 non-null  float64\n",
      " 4   product_height_cm      127570 non-null  float64\n",
      " 5   product_width_cm       127570 non-null  float64\n",
      "dtypes: float64(4), object(2)\n",
      "memory usage: 5.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_products.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1738034",
   "metadata": {},
   "source": [
    "This combined products data has:\n",
    "\n",
    "- 6 columns and 127,594 rows\n",
    "- missing values observed across all columns\n",
    "- correct data types\n",
    "\n",
    "### Overall dataset structures\n",
    "This dataset seems to be structurally sound, with the only issue being missing values in some columns.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17eed29",
   "metadata": {},
   "source": [
    "# **3. Areas of Analysis**\n",
    "Since there are 23 columns in total, there's quite a few areas of analysis that we can choose.\n",
    "\n",
    "##### Lead Time\n",
    "\n",
    "Lead time is one of the many aspects of a supply chain that reflects how efficient a company is. In this analysis we'll be able to see how efficient this company is at handling orders to delivery. \n",
    "\n",
    "##### On-Time Delivery\n",
    "On-time delivery is another important metric in the supply chain. We will be comparing how many recorded shipments were on time, early, or late. \n",
    "\n",
    "##### Ordered Items Category per Area\n",
    "The number of each product category being ordered per area could imply real needs that the company could focus on providing more\n",
    "\n",
    "However, this analysis will focus on top 5 most frequently purchased items only to avoid excessive visual complexity.\n",
    "\n",
    "##### Payment Type Preference and Installments per Area\n",
    "The type of payment chosen by customers and the number of payment installments in each area could potentially show the financial states and spending habits of the customers in the area. \n",
    "\n",
    "However, this analysis will be done at an aggregate level, with regional comparisons limited to the highest-volume states to maintain interpretability.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ed7f59",
   "metadata": {},
   "source": [
    "# **4. Analysis**\n",
    "Following section 3, this section will be split based on the areas of analysis defined previously.\n",
    "\n",
    "## **4.1. Overall Lead Time Analysis**\n",
    ">*What is the average lead time for each states?*\n",
    "\n",
    "Lead time is one of the most impactful metric in a company's supply chain. It reflects how efficient a company is at handling received orders, processing it, to then sipping it to the customers. Longer lead time does not necessarily mean bad because different products may take different amounts of time to be delivered. Thus, in this analysis, we will only be analyzing the average lead time per state.\n",
    "\n",
    "### 4.1.1. Data Processing\n",
    "We will be using the Order data to get our lead time. Firstly, we will need to convert the timestamps and date data into proper datetime format.\n",
    "\n",
    "The data we will be using are:\n",
    "- `order_purchase_timestamp`\n",
    "- `order_delivered_timestamp`\n",
    "\n",
    "First, let's see how many missing values are in these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0b8fd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_purchase_timestamp\n",
       "False    127595\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count missing values\n",
    "df_orders[\"order_purchase_timestamp\"].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e40a407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_delivered_timestamp\n",
       "False    87427\n",
       "True     40168\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count missing values\n",
    "df_orders[\"order_delivered_timestamp\"].isna().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fba78f",
   "metadata": {},
   "source": [
    "From the inspection above, it seems that the purchase record is complete but unfortunately **30% of the actual delivery record data is missing**. This is a significant amount so we will not be able to imput them nor can we simply ignore them. \n",
    "\n",
    "For now, let's convert the timestamps into datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06469154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 127595 entries, 0 to 127594\n",
      "Data columns (total 7 columns):\n",
      " #   Column                         Non-Null Count   Dtype         \n",
      "---  ------                         --------------   -----         \n",
      " 0   order_id                       127595 non-null  object        \n",
      " 1   customer_id                    127595 non-null  object        \n",
      " 2   order_purchase_timestamp       127595 non-null  datetime64[ns]\n",
      " 3   order_approved_at              127579 non-null  object        \n",
      " 4   order_status                   89316 non-null   object        \n",
      " 5   order_delivered_timestamp      87427 non-null   datetime64[ns]\n",
      " 6   order_estimated_delivery_date  89316 non-null   datetime64[ns]\n",
      "dtypes: datetime64[ns](3), object(4)\n",
      "memory usage: 6.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# Convert to datetime\n",
    "df_orders[\"order_purchase_timestamp\"] = pd.to_datetime(df_orders[\"order_purchase_timestamp\"])\n",
    "df_orders[\"order_delivered_timestamp\"] = pd.to_datetime(df_orders[\"order_delivered_timestamp\"])\n",
    "df_orders[\"order_estimated_delivery_date\"] = pd.to_datetime(df_orders[\"order_estimated_delivery_date\"])\n",
    "df_orders.to_csv('all_orders.csv')\n",
    "df_orders.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac7fc17",
   "metadata": {},
   "source": [
    "These columns have now been covnerted to datetime formats. Now, let's look deeper into the missing values.We'll first try to compare these missing values to their last order status. The code below will show them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "cd581234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_status  order_delivered_timestamp\n",
       "approved      NaN                            2\n",
       "unavailable   NaN                            2\n",
       "delivered     NaN                            6\n",
       "invoiced      NaN                          266\n",
       "processing    NaN                          273\n",
       "canceled      NaN                          404\n",
       "shipped       NaN                          936\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_orders[df_orders[\"order_delivered_timestamp\"].isnull()].groupby(\"order_status\")[\"order_delivered_timestamp\"].value_counts(dropna=False).sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ffe898",
   "metadata": {},
   "source": [
    "What the code does:\n",
    "- `df_orders[df_orders[\"order_delivered_timestamp\"].isnull()]` -show only rows with **missing `ordered_delivered_timestamps` values**\n",
    "- grouping the result by their corresponding order statuses\n",
    "- use `dropna=False` to keep the `NaN` so they can be counted\n",
    "\n",
    "The result of that snippet tells us how many missing delivery timestamps for each order status. \n",
    "- `canceled` can be safely assumed that the deliveries were cancelled, thus will never have delivery timestamps. \n",
    "- `unavailable` could mean that the data simply was unavailable during the collection phase. Although the actual reasons were unknown. \n",
    "- On the exception of the `delivered` status having 6 missing values, the rest of the order statuses can be safely assummed that these were outstanding orders that were still in process and haven't reached the customer at the time of data collection. \n",
    "\n",
    "Since there are only 6 orders with `delivered` status not having delivery timestamps and the rest of the statuses being reasonable for not having delivery timestamps, it is safe to ignore them in the lead-time calculation analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f97959",
   "metadata": {},
   "source": [
    "### 4.1.2. Lead-Time Calculation\n",
    "For the analysis, we will be calculating the average lead time per area. To do this, we will need to join the orders database with the customer database.\n",
    "\n",
    "To join tables, we can use `merge`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe81d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 87427 entries, 38279 to 127594\n",
      "Data columns (total 10 columns):\n",
      " #   Column                         Non-Null Count  Dtype         \n",
      "---  ------                         --------------  -----         \n",
      " 0   order_id                       87427 non-null  object        \n",
      " 1   customer_id                    87427 non-null  object        \n",
      " 2   order_purchase_timestamp       87427 non-null  datetime64[ns]\n",
      " 3   order_approved_at              87418 non-null  object        \n",
      " 4   order_status                   87427 non-null  object        \n",
      " 5   order_delivered_timestamp      87427 non-null  datetime64[ns]\n",
      " 6   order_estimated_delivery_date  87427 non-null  datetime64[ns]\n",
      " 7   customer_zip_code_prefix       87427 non-null  int64         \n",
      " 8   customer_city                  87427 non-null  object        \n",
      " 9   customer_state                 87427 non-null  object        \n",
      "dtypes: datetime64[ns](3), int64(1), object(6)\n",
      "memory usage: 7.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Merge databases\n",
    "df_orders_customer = df_orders.merge(\n",
    "    df_cust,\n",
    "    on=\"customer_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Convert datetime columns inito datetime again\n",
    "df_orders_customer[\"order_purchase_timestamp\"] = pd.to_datetime(df_orders_customer[\"order_purchase_timestamp\"])\n",
    "df_orders_customer[\"order_delivered_timestamp\"] = pd.to_datetime(df_orders_customer[\"order_delivered_timestamp\"])\n",
    "df_orders_customer[\"order_estimated_delivery_date\"] = pd.to_datetime(df_orders_customer[\"order_estimated_delivery_date\"])\n",
    "\n",
    "# Remove undelivered rows\n",
    "df_orders_customer = df_orders_customer[df_orders_customer[\"order_delivered_timestamp\"].notnull()]\n",
    "\n",
    "df_orders_customer.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8814f41",
   "metadata": {},
   "source": [
    "Now that the database has been merged, we can create a new column as the lead-time column. To calculate the lead-time we will be substracting the delivered timestamps with the purchased timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d436d6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new column to calculate lead-time\n",
    "df_orders_customer[\"lead_time\"] = (df_orders_customer[\"order_delivered_timestamp\"] - df_orders_customer[\"order_purchase_timestamp\"]).dt.days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52355875",
   "metadata": {},
   "source": [
    "The code above:\n",
    "- add new column `lead_time`\n",
    "- its cells are filled with substraction result\n",
    "- `dt.days` convert the values into how many days\n",
    "\n",
    "Now that we have the lead-time values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "eaf77806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_state\n",
       "RR    27.972973\n",
       "AP    27.522388\n",
       "AM    25.847826\n",
       "AL    24.206154\n",
       "PA    22.794743\n",
       "Name: lead_time, dtype: float64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5_lead_time = df_orders_customer.groupby(\"customer_state\")[\"lead_time\"].mean().nlargest(n=5)\n",
    "top_5_lead_time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
