{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2c13eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook is working\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "print(\"Notebook is working\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd3dfce",
   "metadata": {},
   "source": [
    "**Data source:** https://www.kaggle.com/datasets/bytadit/ecommerce-order-dataset/data\n",
    "\n",
    "# **1. Introduction**\n",
    "I have 2 purposes for this project. To further practice data analysis with python and to do analysis on an ecommerce and supply chain dataset. \n",
    "\n",
    "The purpose of this project is to epxlore an ecommerce and supply chain dataset and find areas to analyze. Below is a list of the sections in this notebook:\n",
    "\n",
    "1. Data inspection\n",
    "2. Finding areas of inspection\n",
    "3. Data processing and analysis\n",
    "4. Conclusion\n",
    "\n",
    "---\n",
    "\n",
    "# **2. Data Inspection**\n",
    "Before doing anything else, let's check the datasets that we have in the `data` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c373c19d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\2. Areas\\\\Career_Exploration\\\\Data_Analyst\\\\ecommerce_sc_dataset'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Current working directory\n",
    "os.listdir(\"data\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfb6325",
   "metadata": {},
   "source": [
    "Our dataset seems to be intended for machine learning as it is split into training and test data. For this specific project we'll focus mainly on EDA, wo we will not be modifying the data in any way. Thus it is safe to combine them both.\n",
    "\n",
    "## 2.1. Concatenating datasets\n",
    "First, let's read the training data into python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ec3d634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get into 'train' working directory\n",
    "os.chdir(\"d:\\\\2. Areas\\\\Career_Exploration\\\\Data_Analyst\\\\ecommerce_sc_dataset\\\\data\\\\train\")\n",
    "os.listdir(\".\")\n",
    "\n",
    "# Reading the files into python\n",
    "df_tr_cust = pd.read_csv(\"train_Customers.csv\")\n",
    "df_tr_ordItems = pd.read_csv(\"train_OrderItems.csv\")\n",
    "df_tr_orders = pd.read_csv(\"train_Orders.csv\")\n",
    "df_tr_payments = pd.read_csv(\"train_Payments.csv\")\n",
    "df_tr_products = pd.read_csv(\"train_Products.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c604be0",
   "metadata": {},
   "source": [
    "Now the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3da89f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get into 'test' working directory\n",
    "os.chdir(\"d:\\\\2. Areas\\\\Career_Exploration\\\\Data_Analyst\\\\ecommerce_sc_dataset\\\\data\\\\test\")\n",
    "os.listdir(\".\")\n",
    "\n",
    "# Reading the files into python\n",
    "df_ts_cust = pd.read_csv(\"test_customers.csv\")\n",
    "df_ts_ordItems = pd.read_csv(\"test_OrderItems.csv\")\n",
    "df_ts_orders = pd.read_csv(\"test_Orders.csv\")\n",
    "df_ts_payments = pd.read_csv(\"test_Payments.csv\")\n",
    "df_ts_products = pd.read_csv(\"test_Products.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06731d64",
   "metadata": {},
   "source": [
    "Now that we have the data in python, we will now create copies and work with them instead of the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1a131df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create copies\n",
    "df_cust = pd.concat([df_ts_cust.copy(),df_tr_cust.copy()], ignore_index=True)\n",
    "df_ordItems = pd.concat([df_ts_ordItems.copy(),df_tr_ordItems.copy()], ignore_index=True)\n",
    "df_orders = pd.concat([df_ts_orders.copy(),df_tr_orders.copy()], ignore_index=True)\n",
    "df_payments = pd.concat([df_ts_payments.copy(),df_tr_payments.copy()], ignore_index=True)\n",
    "df_products = pd.concat([df_ts_products.copy(),df_tr_products.copy()], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "94121274",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_cust, df_ordItems, df_orders, df_payments, df_products], ignore_index=True)\n",
    "df_all.to_csv('temp_all_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5de818",
   "metadata": {},
   "source": [
    "## 2.2. Inspection\n",
    "Now that we have all the datasets combined, let's inspect each one.\n",
    "\n",
    "#### Customer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a06f3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 127595 entries, 0 to 127594\n",
      "Data columns (total 4 columns):\n",
      " #   Column                    Non-Null Count   Dtype \n",
      "---  ------                    --------------   ----- \n",
      " 0   customer_id               127595 non-null  object\n",
      " 1   customer_zip_code_prefix  127595 non-null  int64 \n",
      " 2   customer_city             127595 non-null  object\n",
      " 3   customer_state            127595 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 3.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_cust.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6f2a04",
   "metadata": {},
   "source": [
    "The combined customer has:\n",
    "\n",
    "- 4 columns and 127,594 row\n",
    "- no missing values\n",
    "- correct data types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7461cc6",
   "metadata": {},
   "source": [
    "#### Order Items data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "745c97fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 127595 entries, 0 to 127594\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   order_id          127595 non-null  object \n",
      " 1   product_id        127595 non-null  object \n",
      " 2   seller_id         127595 non-null  object \n",
      " 3   price             127595 non-null  float64\n",
      " 4   shipping_charges  127595 non-null  float64\n",
      "dtypes: float64(2), object(3)\n",
      "memory usage: 4.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_ordItems.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46cc926",
   "metadata": {},
   "source": [
    "This combined order items data has:\n",
    "\n",
    "- 5 columns and 125,594 rows\n",
    "- no missing values\n",
    "- correct data types\n",
    "\n",
    "#### Order data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e97d9a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 127595 entries, 0 to 127594\n",
      "Data columns (total 7 columns):\n",
      " #   Column                         Non-Null Count   Dtype \n",
      "---  ------                         --------------   ----- \n",
      " 0   order_id                       127595 non-null  object\n",
      " 1   customer_id                    127595 non-null  object\n",
      " 2   order_purchase_timestamp       127595 non-null  object\n",
      " 3   order_approved_at              127579 non-null  object\n",
      " 4   order_status                   89316 non-null   object\n",
      " 5   order_delivered_timestamp      87427 non-null   object\n",
      " 6   order_estimated_delivery_date  89316 non-null   object\n",
      "dtypes: object(7)\n",
      "memory usage: 6.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_orders.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9aab577f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 127595 entries, 0 to 127594\n",
      "Data columns (total 7 columns):\n",
      " #   Column                         Non-Null Count   Dtype \n",
      "---  ------                         --------------   ----- \n",
      " 0   order_id                       127595 non-null  object\n",
      " 1   customer_id                    127595 non-null  object\n",
      " 2   order_purchase_timestamp       127595 non-null  object\n",
      " 3   order_approved_at              127579 non-null  object\n",
      " 4   order_status                   89316 non-null   object\n",
      " 5   order_delivered_timestamp      87427 non-null   object\n",
      " 6   order_estimated_delivery_date  89316 non-null   object\n",
      "dtypes: object(7)\n",
      "memory usage: 6.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_orders.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960fa0a3",
   "metadata": {},
   "source": [
    "This combined order data has:\n",
    "\n",
    "- 7 columns and 127,594 rows\n",
    "- missing values in columns `order_approved_at`, `order_status`, `order_delivered_timestamp`, and `order_estimated_delivery_date`.\n",
    "- correct data types, however dates and timestamps will need to be covnerted into their proper formats in the processing.\n",
    "\n",
    "#### Payments data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee2e5602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 127595 entries, 0 to 127594\n",
      "Data columns (total 5 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   order_id              127595 non-null  object \n",
      " 1   payment_sequential    127595 non-null  int64  \n",
      " 2   payment_type          127595 non-null  object \n",
      " 3   payment_installments  127595 non-null  int64  \n",
      " 4   payment_value         127595 non-null  float64\n",
      "dtypes: float64(1), int64(2), object(2)\n",
      "memory usage: 4.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_payments.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1b5811",
   "metadata": {},
   "source": [
    "This combined payments data has:\n",
    "\n",
    "- 5 columns and 127,594 rows\n",
    "- no missing values\n",
    "- correct data types\n",
    "\n",
    "#### Products data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e05c8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 127595 entries, 0 to 127594\n",
      "Data columns (total 6 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   product_id             127595 non-null  object \n",
      " 1   product_category_name  127119 non-null  object \n",
      " 2   product_weight_g       127570 non-null  float64\n",
      " 3   product_length_cm      127570 non-null  float64\n",
      " 4   product_height_cm      127570 non-null  float64\n",
      " 5   product_width_cm       127570 non-null  float64\n",
      "dtypes: float64(4), object(2)\n",
      "memory usage: 5.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_products.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1738034",
   "metadata": {},
   "source": [
    "This combined products data has:\n",
    "\n",
    "- 6 columns and 127,594 rows\n",
    "- missing values observed across all columns\n",
    "- correct data types\n",
    "\n",
    "### Overall dataset structures\n",
    "This dataset seems to be structurally sound, with the only issue being missing values in some columns.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17eed29",
   "metadata": {},
   "source": [
    "# **3. Areas of Analysis**\n",
    "Since there are 23 columns in total, there's quite a few areas of analysis that we can choose.\n",
    "\n",
    "##### Lead Time\n",
    "\n",
    "Lead time is one of the many aspects of a supply chain that reflects how efficient a company is. In this analysis we'll be able to see how efficient this company is at handling orders to delivery. \n",
    "\n",
    "##### On-Time Delivery\n",
    "On-time delivery is another important metric in the supply chain. We will be comparing how many recorded shipments were on time, early, or late. \n",
    "\n",
    "##### Ordered Items Category per Area\n",
    "The number of each product category being ordered per area could imply real needs that the company could focus on providing more\n",
    "\n",
    "However, this analysis will focus on top 5 most frequently purchased items only to avoid excessive visual complexity.\n",
    "\n",
    "##### Payment Type Preference and Installments per Area\n",
    "The type of payment chosen by customers and the number of payment installments in each area could potentially show the financial states and spending habits of the customers in the area. \n",
    "\n",
    "However, this analysis will be done at an aggregate level, with regional comparisons limited to the highest-volume states to maintain interpretability."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
